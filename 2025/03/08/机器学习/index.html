

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">

  <link rel="apple-touch-icon" sizes="76x76" href="/img/fluid.png">
  <link rel="icon" href="/img/fluid.png">
  

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="pp">
  <meta name="keywords" content="">
  
    <meta name="description" content="OverviewDefinitionField of study that gives computers the ability to learn without being explicitly programmed. Machine learning algorithms Supervised learning Unsupervised learning  Recommender syste">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine_learning">
<meta property="og:url" content="http://example.com/2025/03/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.html">
<meta property="og:site_name" content="pp&#39;s blog">
<meta property="og:description" content="OverviewDefinitionField of study that gives computers the ability to learn without being explicitly programmed. Machine learning algorithms Supervised learning Unsupervised learning  Recommender syste">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/images/Cost_Function.png">
<meta property="og:image" content="http://example.com/images/The_function_of_w.png">
<meta property="og:image" content="http://example.com/images/J(w,b).png">
<meta property="og:image" content="http://example.com/images/Gradient_Descent_Algorithm.png">
<meta property="og:image" content="http://example.com/images/Gradient_Descent.png">
<meta property="og:image" content="http://example.com/images/Gradient_Descent_for_Linear_Regression.png">
<meta property="og:image" content="http://example.com/images/Multiple_Variables.png">
<meta property="og:image" content="http://example.com/images/Multiple_linear_regression.png">
<meta property="og:image" content="http://example.com/images/Vectorization.png%22">
<meta property="og:image" content="http://example.com/images/Gradient_Descent_for_Linear_Regression.png">
<meta property="og:image" content="http://example.com/images/Feature_Scaling.png">
<meta property="og:image" content="http://example.com/images/Sigmoid_Function.png">
<meta property="og:image" content="http://example.com/images/Sigmoid_Function_for_Mulitiple_Regression.png">
<meta property="og:image" content="http://example.com/images/Square_error_cost.png">
<meta property="og:image" content="http://example.com/images/Cost_Function_for_Logistic_Regression.png">
<meta property="og:image" content="http://example.com/images/Simplified_Cost_Function.png">
<meta property="og:image" content="http://example.com/images/Gradient_Desctent_Implementation_for_Logistic_Regression.png">
<meta property="og:image" content="http://example.com/images/Difference_between_Logistic_Regression_and_Linear_Regression.png">
<meta property="og:image" content="http://example.com/images/Fitting.png">
<meta property="og:image" content="http://example.com/images/Regularization.png">
<meta property="og:image" content="http://example.com/images/Regularized_Linear_Regression.png">
<meta property="og:image" content="http://example.com/images/Regularized_Logistic_Regression.png">
<meta property="og:image" content="http://example.com/images/Demand_Prediction.png">
<meta property="og:image" content="http://example.com/images/Layer.png">
<meta property="og:image" content="http://example.com/images/Multiple_hidden_layers.png">
<meta property="og:image" content="http://example.com/images/Neural_network_layer.png">
<meta property="og:image" content="http://example.com/images/general_form.png">
<meta property="og:image" content="http://example.com/images/Forword_Prop.png">
<meta property="og:image" content="http://example.com/images/General_implemention_of_forward_propagation.png">
<meta property="og:image" content="http://example.com/images/Loops_vs_Vetetorization.png">
<meta property="og:image" content="http://example.com/images/Matrix_multiplication_in_numpy.png">
<meta property="og:image" content="http://example.com/images/Matrix_multiplication_in_tensorflow.png">
<meta property="og:image" content="http://example.com/images/Model_Training_Steps.png">
<meta property="og:image" content="http://example.com/images/Softmax.png">
<meta property="og:image" content="http://example.com/images/Cost.png">
<meta property="og:image" content="http://example.com/images/Neural_Network_with_Softmax_output.png">
<meta property="og:image" content="http://example.com/images/MNIST.png">
<meta property="og:image" content="http://example.com/images/Improved_implementation_of_Logistic_regression.png">
<meta property="og:image" content="http://example.com/images/Improved_implementation_of_Softmax_regression.png">
<meta property="og:image" content="http://example.com/images/Multilabel_Classification.png">
<meta property="og:image" content="http://example.com/images/Adam.png">
<meta property="og:image" content="http://example.com/images/Convolutional_Neural_Network.png">
<meta property="og:image" content="http://example.com/images/Train/test_procedure_for_linear_regression.png">
<meta property="og:image" content="http://example.com/images/Train/test_procedure_for_classification_problem.png">
<meta property="og:image" content="http://example.com/images/Train/Model_Selection.png">
<meta property="og:image" content="http://example.com/images/Train/Cross_validation.png">
<meta property="article:published_time" content="2025-03-08T07:09:33.681Z">
<meta property="article:modified_time" content="2025-03-14T12:01:19.053Z">
<meta property="article:author" content="pp">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/images/Cost_Function.png">
  
  
  
  <title>Machine_learning - pp&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1749284_5i9bdhy70f8.css">



<link rel="stylesheet" href="//at.alicdn.com/t/c/font_1736178_k526ubmyhba.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.8","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false},"umami":{"src":null,"website_id":null,"domains":null,"start_time":"2024-01-01T00:00:00.000Z","token":null,"api_server":null}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>pp&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>首页</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>归档</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>分类</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>标签</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>关于</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Machine_learning"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2025-03-08 15:09" pubdate>
          2025年3月8日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          532 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          5 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Machine_learning</h1>
            
            
              <div class="markdown-body">
                
                <h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Field of study that gives computers the ability to learn without being explicitly programmed.</p>
<h2 id="Machine-learning-algorithms"><a href="#Machine-learning-algorithms" class="headerlink" title="Machine learning algorithms"></a>Machine learning algorithms</h2><ul>
<li>Supervised learning</li>
<li>Unsupervised learning </li>
<li>Recommender systems</li>
<li>Reinforcement learnin</li>
</ul>
<h3 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h3><ul>
<li>Regression</li>
<li>Classification<br>Key charateristic:input–&gt;output<br><strong>Regression</strong>:Predicts a number from infinitely many possible numbers.<br><strong>Classification</strong>:Predicts catagories from small number of possible outputs.Categories don’t have to be numbers.<br>When it comes to two or more inputs:The learning algorithm has to decide how to fit a boundary line to this data.</li>
</ul>
<h3 id="Unsupervised-learning"><a href="#Unsupervised-learning" class="headerlink" title="Unsupervised learning"></a>Unsupervised learning</h3><p>Find something interesting in unlabeld data.<br>Key charateristc:Data only comes with inputs x,but not output labels y.Algorithm has to find structure in the data.</p>
<ul>
<li>Clustering</li>
<li>Anomaly detection</li>
<li>Dimensionality reduction<br><strong>Clustering</strong>: Places the unlabeled data into different clusters,automatically finding stucture into data and figuring out what are the major types of individuals.<br><strong>Anomaly detection</strong>:Finds unusual data points.<br><strong>Dimensionality reduction</strong>：Compress data using fewer numbers.</li>
</ul>
<hr>
<h2 id="Jupyter-Notebooks"><a href="#Jupyter-Notebooks" class="headerlink" title="Jupyter Notebooks"></a>Jupyter Notebooks</h2><h1 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h1><p>Training Set–&gt;learing algorithms–&gt;function:model<br>Linear Regressionin with one variable:y&#x3D;wx+b</p>
<h2 id="Cost-Function"><a href="#Cost-Function" class="headerlink" title="Cost Function"></a>Cost Function</h2><p>f(x)&#x3D;wx+b w,b:parameters&#x2F;coeffients&#x2F;weights<br><img src="/images/Cost_Function.png" srcset="/img/loading.gif" lazyload alt="pic" title="Cost Function"><br>Cost Function:Square error cost function<br>Goal:Minimize J(w,b)<br><img src="/images/The_function_of_w.png" srcset="/img/loading.gif" lazyload alt="pic" title="The function of w"><br><img src="/images/J(w,b).png" srcset="/img/loading.gif" lazyload alt="pic" title="J(w,b) of Linear Function"></p>
<h2 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h2><p>Outline:</p>
<ul>
<li>Start with some w,b</li>
<li>Keep changing w,b to reduce J(w,b)</li>
<li>Until we settle at or near a minimum</li>
</ul>
<h3 id="Implement-Gradient-Descent"><a href="#Implement-Gradient-Descent" class="headerlink" title="Implement Gradient Descent"></a>Implement Gradient Descent</h3><p><img src="/images/Gradient_Descent_Algorithm.png" srcset="/img/loading.gif" lazyload alt="pic" title="Gradient Descent Algorithm"><br>α：Learing Rate(between 0~1),controls how big of step you take downhill.<br>Derivative:Decide the direction to take step.<br>Repeat until convergence–&gt;reach the point at a local<br>minimum where the parameters w and b no longer change much with each additional step that you take.</p>
<h3 id="Gradient-Descent-Intuition"><a href="#Gradient-Descent-Intuition" class="headerlink" title="Gradient Descent Intuition"></a>Gradient Descent Intuition</h3><p><img src="/images/Gradient_Descent.png" srcset="/img/loading.gif" lazyload alt="pic" title="Gradient Descent Intuition"></p>
<h3 id="Learning-Rate"><a href="#Learning-Rate" class="headerlink" title="Learning Rate"></a>Learning Rate</h3><p>If α is too small, Gradient descent may be slow.<br>If α is too large, Gradient descent may:</p>
<ul>
<li>Overshoot, never reach minimum</li>
<li>Fail to converge, diverge<br>Gradient Descent can reach local minimum with fixed learning rate.<br>Near a local minimum,</li>
<li>Derivative becomes smaller</li>
<li>Update steps become smaller</li>
</ul>
<h3 id="Gradient-Descent-for-Linear-Regression"><a href="#Gradient-Descent-for-Linear-Regression" class="headerlink" title="Gradient Descent for Linear Regression"></a>Gradient Descent for Linear Regression</h3><p><img src="/images/Gradient_Descent_for_Linear_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Gradient Descent for Linear Regression"><br>“Batch” gradient descent: Each step of gradient descent uses all the training example.</p>
<h2 id="Linear-Regression-with-Multiple-Variables"><a href="#Linear-Regression-with-Multiple-Variables" class="headerlink" title="Linear Regression with Multiple Variables"></a>Linear Regression with Multiple Variables</h2><p><img src="/images/Multiple_Variables.png" srcset="/img/loading.gif" lazyload alt="pic" title="Multiple Variables"><br>Models:</p>
<ul>
<li>Previously: f(x)&#x3D;wx+b</li>
<li>Multiple linear regression: f(x)&#x3D; w_1<em>x_1+w_2</em>x_2+w_3<em>x_3+w_4</em>x_4+b<br><img src="/images/Multiple_linear_regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Multiple linear regression"></li>
</ul>
<h3 id="Vectorization"><a href="#Vectorization" class="headerlink" title="Vectorization"></a>Vectorization</h3><p><img src="/images/Vectorization.png%22" srcset="/img/loading.gif" lazyload alt="pic" title="Vectorization"> </p>
<h3 id="Gradient-Descent-for-Multiple-Regression"><a href="#Gradient-Descent-for-Multiple-Regression" class="headerlink" title="Gradient Descent for Multiple Regression"></a>Gradient Descent for Multiple Regression</h3><p><img src="/images/Gradient_Descent_for_Linear_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Gradient Descent for Multiple Regressionctorization"><br>Normal equation: A alternative to gradient descent.</p>
<ul>
<li>Only for linear regression</li>
<li>Solve for w,b without iterations<br>Disadvantages:</li>
<li>Doesn’t generalize to other learing algorithms.</li>
<li>Slow when number of features is large.</li>
</ul>
<h2 id="Feature-Scaling"><a href="#Feature-Scaling" class="headerlink" title="Feature Scaling"></a>Feature Scaling</h2><p><img src="/images/Feature_Scaling.png" srcset="/img/loading.gif" lazyload alt="pic" title="Feature Scaling"></p>
<ul>
<li>Mean normalization</li>
<li>Z-score normalization</li>
</ul>
<h3 id="Checking-Gradient-Descent-for-Converge"><a href="#Checking-Gradient-Descent-for-Converge" class="headerlink" title="Checking Gradient Descent for Converge"></a>Checking Gradient Descent for Converge</h3><ul>
<li>Learning Curve</li>
<li>Automatic converge test: let epsilon be 0.001. If J(w,b) decreses by ≤ epsilon in one iteration, declare convergence.</li>
</ul>
<h3 id="Choosiong-the-Learning-Rate"><a href="#Choosiong-the-Learning-Rate" class="headerlink" title="Choosiong the Learning Rate"></a>Choosiong the Learning Rate</h3><p>With a small enough α, J(w,b) should decrease on every iteration.</p>
<h2 id="Feature-Engineering"><a href="#Feature-Engineering" class="headerlink" title="Feature Engineering"></a>Feature Engineering</h2><p>Feature Engineering: Using intuition to design new features, by transforming or combining original features.</p>
<h2 id="Polynomial-Regression"><a href="#Polynomial-Regression" class="headerlink" title="Polynomial Regression"></a>Polynomial Regression</h2><p>Features: x, x squared, x cubed…(Scikit-learn)</p>
<h1 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h1><ul>
<li>Negative class</li>
<li>Positive class</li>
</ul>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p>Sigmoid function:logistic function<br><img src="/images/Sigmoid_Function.png" srcset="/img/loading.gif" lazyload alt="pic" title="Sigmoid Function"></p>
<h3 id="Decision-Boundary"><a href="#Decision-Boundary" class="headerlink" title="Decision Boundary"></a>Decision Boundary</h3><p><img src="/images/Sigmoid_Function_for_Mulitiple_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Sigmoid Function for Mulitiple Regression"></p>
<h3 id="Cost-Function-for-Logistic-Regression"><a href="#Cost-Function-for-Logistic-Regression" class="headerlink" title="Cost Function for Logistic Regression"></a>Cost Function for Logistic Regression</h3><p>Squared error cost:</p>
<ul>
<li>Linear regression: convex cost function</li>
<li>Logistic regression: non-convex function<br><img src="/images/Square_error_cost.png" srcset="/img/loading.gif" lazyload alt="pic" title="Square error cost"><br>Cost Function: average loss over all training samples.<br>Loss Function: predicts the target for single sample </li>
<li>Target: Measuring the Quality of Predicted Probabilities<br>In a binary classification problem, the model outputs a probability value, which represents the probability that a given sample belongs to class 1.</li>
<li>Maximum Likelihood Estimation</li>
<li>Taking the Log to Obtain the Log-Likelihood</li>
<li>Binary Cross-Entropy Loss<br><img src="/images/Cost_Function_for_Logistic_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Cost Function for Logistic Regression"><br>When y(i)&#x3D;1:if the model predicts a high probility for class 1, the loss is small; otherwise, the loss is large. When y(i)&#x3D;0, if the model predicts a low probability for class 1 (i.e., a high probability for class 0), the loss is small; otherwise, the loss is large.</li>
</ul>
<h3 id="Simplified-Cost-Function"><a href="#Simplified-Cost-Function" class="headerlink" title="Simplified Cost Function"></a>Simplified Cost Function</h3><p><img src="/images/Simplified_Cost_Function.png" srcset="/img/loading.gif" lazyload alt="pic" title="Simplified Cost Function"></p>
<h3 id="Gradient-Desctent-Implementation"><a href="#Gradient-Desctent-Implementation" class="headerlink" title="Gradient Desctent Implementation"></a>Gradient Desctent Implementation</h3><p>Goal: Find w,b, try to estimate the probability that the label Y is 1.<br>Same concepts:</p>
<ul>
<li>Minitor gradient descent(learning curve)</li>
<li>Vectorized implementation<br><img src="/images/Gradient_Desctent_Implementation_for_Logistic_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Gradient Desctent Implementation for Logistic Regression"><br><img src="/images/Difference_between_Logistic_Regression_and_Linear_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Difference between Logistic Regression and Linear Regression"></li>
</ul>
<h2 id="Regularization-to-Reduce-Overfitting"><a href="#Regularization-to-Reduce-Overfitting" class="headerlink" title="Regularization to Reduce Overfitting"></a>Regularization to Reduce Overfitting</h2><h3 id="The-problem-of-overfitting"><a href="#The-problem-of-overfitting" class="headerlink" title="The problem of overfitting"></a>The problem of overfitting</h3><p><img src="/images/Fitting.png" srcset="/img/loading.gif" lazyload alt="pic" title="Three Regression Examples"></p>
<ul>
<li>Does not fit the training set well: high bias–&gt;underfit</li>
<li>Fits training set pretty well: generalization</li>
<li>Fits the training set extremely well: high variance–&gt;overfit</li>
</ul>
<h3 id="Addresssing-Overfitting"><a href="#Addresssing-Overfitting" class="headerlink" title="Addresssing Overfitting"></a>Addresssing Overfitting</h3><ul>
<li>Collect more training data</li>
<li>Select features to include&#x2F;exclude</li>
<li>Regularization: encourage the learning algorithm to shrink the values of parameters without neccessarily demanding that the parameter is set to exactly zero.</li>
</ul>
<h4 id="Cost-Function-with-Regularization"><a href="#Cost-Function-with-Regularization" class="headerlink" title="Cost Function with Regularization"></a>Cost Function with Regularization</h4><p>Lambda: regularization parameter<br>If lambda is too enormous–&gt;underfit<br>If lambda is too small–&gt;overfit<br><img src="/images/Regularization.png" srcset="/img/loading.gif" lazyload alt="pic" title="Cost Function with Regularization"></p>
<h4 id="Regularized-Linear-Regression"><a href="#Regularized-Linear-Regression" class="headerlink" title="Regularized Linear Regression"></a>Regularized Linear Regression</h4><p><img src="/images/Regularized_Linear_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Cost Function with Regularization"></p>
<h4 id="Regularuzed-Logistic-Regression"><a href="#Regularuzed-Logistic-Regression" class="headerlink" title="Regularuzed Logistic Regression"></a>Regularuzed Logistic Regression</h4><p><img src="/images/Regularized_Logistic_Regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Regularuzed Logistic Regression"></p>
<h1 id="Advanced-learning-algorithms"><a href="#Advanced-learning-algorithms" class="headerlink" title="Advanced learning algorithms"></a>Advanced learning algorithms</h1><h2 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h2><p>Simplified mathematical model of neuron: inputs–&gt;neuron–&gt;outputs</p>
<h3 id="inference-prediction"><a href="#inference-prediction" class="headerlink" title="inference(prediction)"></a>inference(prediction)</h3><p><img src="/images/Demand_Prediction.png" srcset="/img/loading.gif" lazyload alt="pic" title="Demand Prediction"></p>
<ul>
<li>Layer: A group of neurons which take as input the same or similiar features and that in turn output a few numbers together.</li>
<li>Affordability, awareness, perceived quality–&gt;<strong>activations</strong><br><img src="/images/Layer.png" srcset="/img/loading.gif" lazyload alt="pic" title="Layer"></li>
<li>input layer: 4 numbers(vector)–&gt;hidden layer: 3 numbers–&gt;ouput layer: 1 numbers(vector)</li>
<li>Why called hidden layer: The data set tells you what is x and what is y, so you get data that tells you what are the correct inputs and the correct outputs, but the data set doesn’t tell you what are the correct values for affordability, awareness, perceived quality, so the correct data is hidden in the training set.</li>
<li>Cover up the left half of this diagram: a  logistic regression algorithm that is taking as input affordability, awareness, perceived quality of a t-shirt and using these three features to estimate the probability of the t-shirt being a top seller. What the neural network does is instead of you needing  to manually engineer the features, it can learn.</li>
<li>Multiple hidden layers(Multilayer perception): neural network architecture<br><img src="/images/Multiple_hidden_layers.png" srcset="/img/loading.gif" lazyload alt="pic" title="Multiple hidden layers"></li>
</ul>
<h4 id="Example-Recognizing-Images"><a href="#Example-Recognizing-Images" class="headerlink" title="Example: Recognizing Images"></a>Example: Recognizing Images</h4><ul>
<li>Goal: Train a network with a million pixel brightness values, and outputs the indentity of the person in the picture.</li>
<li>Hidden layer: the 1st:looking for a little vertical line or edge; a oriented line; a line that orientation…the 2nd: group together; the 3rd: face </li>
<li>A remarkable feature: the neural network can learn these features detectors at the hidden layers all by itself.</li>
</ul>
<h4 id="Neural-network-layer"><a href="#Neural-network-layer" class="headerlink" title="Neural network layer"></a>Neural network layer</h4><p><img src="/images/Neural_network_layer.png" srcset="/img/loading.gif" lazyload alt="pic" title="Neural network layer"> </p>
<h4 id="More-complex-neural-networks"><a href="#More-complex-neural-networks" class="headerlink" title="More complex neural networks"></a>More complex neural networks</h4><p><img src="/images/general_form.png" srcset="/img/loading.gif" lazyload alt="pic" title="General Form"><br>j: jth neuron<br>j: jth neuron<br>[l]: lth layer<br>g: sigmoid function–&gt;<strong>activation function</strong><br>Each unit is a single neuron in the layer</p>
<h4 id="Inference-making-predictions-forward-propagation"><a href="#Inference-making-predictions-forward-propagation" class="headerlink" title="Inference: making predictions(forward propagation)"></a>Inference: making predictions(forward propagation)</h4><p>A handwritten digit recognition sample:<br>Forward  propagation: computation goes from left to right, propagating the activations of the neurons. These computations in the forward direction and this is in constrast to a different algorithm called backword propagation or back propagation.</p>
<h4 id="Building-the-model-using-TensorFlow"><a href="#Building-the-model-using-TensorFlow" class="headerlink" title="Building the model using TensorFlow"></a>Building the model using TensorFlow</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs python">x=np.array([[<span class="hljs-number">200.0</span>,<span class="hljs-number">17.0</span>]])<br>layer_1= Dense(units=<span class="hljs-number">3</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)<br>a1= layer_1(x)<span class="hljs-comment">#1*3 matrix</span><br></code></pre></td></tr></table></figure>
<ul>
<li>Data in TensorFlow:</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python">x=np.array([[<span class="hljs-number">200</span>,<span class="hljs-number">17</span>]])<span class="hljs-comment">#[200,17] 1*2</span><br>x=np.array([[<span class="hljs-number">200</span>],<br>            [<span class="hljs-number">17</span>]<br>               ]) <span class="hljs-comment">#2*1--&gt;TensorFloW</span><br>x=np.array([<span class="hljs-number">200</span>,<span class="hljs-number">17</span>])<span class="hljs-comment">#1d vector, a linear array with no rows or no columns.--&gt; Linear Regression, Logistic Regression</span><br>tf.Tensor([[<span class="hljs-number">0.2</span> <span class="hljs-number">0.7</span> <span class="hljs-number">0.3</span>]], shape=(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>), dtype=float32)<br><br>layer_2= Dense(units=<span class="hljs-number">3</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)<br>a2= layer_2(a1)<br>tf.Tensor([[<span class="hljs-number">0.8</span>]], shape=(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>), dtype=float32)<br>a2.numpy()<br></code></pre></td></tr></table></figure>
<h4 id="Building-a-neural-network"><a href="#Building-a-neural-network" class="headerlink" title="Building a neural network"></a>Building a neural network</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs python">layer_1= Dense(units=<span class="hljs-number">3</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)<br>layer_2= Dense(units=<span class="hljs-number">1</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)<br>model = Sequential([layer_1, layer_2])<br>x = np.array([[<span class="hljs-number">200</span>,<span class="hljs-number">17</span>],<br>              [<span class="hljs-number">120</span>,<span class="hljs-number">5</span>]<br>              [<span class="hljs-number">425</span>,<span class="hljs-number">20</span>] <br>              [<span class="hljs-number">212</span>,<span class="hljs-number">18</span>]])<br>y = np.array([<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>])<br>model.<span class="hljs-built_in">compile</span>(...)<br>model.fit(x,y)<br>model.predict(x_new)<span class="hljs-comment">#ouput a2</span><br><br>model = Sequential([<br>    Dense(units=<span class="hljs-number">3</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)<br>    Dense(units=<span class="hljs-number">1</span> activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>)])   <br></code></pre></td></tr></table></figure>
<h4 id="Forword-prop-in-a-single-layer"><a href="#Forword-prop-in-a-single-layer" class="headerlink" title="Forword prop in a single layer"></a>Forword prop in a single layer</h4><p><img src="/images/Forword_Prop.png" srcset="/img/loading.gif" lazyload alt="pic" title="Forword Prop"> </p>
<h4 id="General-implemention-of-forward-propagation"><a href="#General-implemention-of-forward-propagation" class="headerlink" title="General implemention of forward propagation"></a>General implemention of forward propagation</h4><p><img src="/images/General_implemention_of_forward_propagation.png" srcset="/img/loading.gif" lazyload alt="pic" title="General implemention of forward propagation"></p>
<h4 id="Is-there-a-path-to-AGI"><a href="#Is-there-a-path-to-AGI" class="headerlink" title="Is there a path to AGI"></a>Is there a path to AGI</h4><ul>
<li>ANI：artificial narrow intelligence</li>
<li>AGI: artificial general intelligence</li>
</ul>
<h4 id="Vectorization-1"><a href="#Vectorization-1" class="headerlink" title="Vectorization"></a>Vectorization</h4><p><img src="/images/Loops_vs_Vetetorization.png" srcset="/img/loading.gif" lazyload alt="pic" title="Loops vs Vetetorization"> </p>
<h5 id="Matrix-multiplication"><a href="#Matrix-multiplication" class="headerlink" title="Matrix multiplication"></a>Matrix multiplication</h5><p><img src="/images/Matrix_multiplication_in_numpy.png" srcset="/img/loading.gif" lazyload alt="pic" title="Matrix multiplication in Numpy"><br><img src="/images/Matrix_multiplication_in_tensorflow.png" srcset="/img/loading.gif" lazyload alt="pic" title="Matrix Multiplication in Tensorflow"></p>
<h3 id="Net-Network-Training"><a href="#Net-Network-Training" class="headerlink" title="Net Network Training"></a>Net Network Training</h3><h4 id="Training-Details"><a href="#Training-Details" class="headerlink" title="Training Details"></a>Training Details</h4><ul>
<li>specify how to compute output given input x and parameters w,b(define model)–&gt;f(x)&#x3D;?</li>
<li>specify loss and cost </li>
<li>train on data to minimiaze J(w,b)<br><img src="/images/Model_Training_Steps.png" srcset="/img/loading.gif" lazyload alt="pic" title="Model Training Steps"></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf <br><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> Sequential<br><span class="hljs-keyword">from</span> tensorflow,keras <span class="hljs-keyword">import</span> Dense<br>    model = Sequential([<br>    Dense(units=<span class="hljs-number">25</span>, activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>),<br>    Dense(units=<span class="hljs-number">15</span> activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>),<br>    Dense(units=<span class="hljs-number">1</span> activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>),<br>                      ]) <br><span class="hljs-keyword">from</span> tensorflow.keras.losses <span class="hljs-keyword">import</span><br>BinaryCrossentropy<br>    model.<span class="hljs-built_in">compile</span>(loss=BinaryCrossentropy())<br><br>    model.fit(X,Y.epochs=<span class="hljs-number">100</span>)<span class="hljs-comment">#number of steps in gradient descent--&gt;compute derivatives for gradient descent using &quot;back propagation&quot;</span><br></code></pre></td></tr></table></figure>
<h4 id="Alternatives-to-the-sigmoid-activation"><a href="#Alternatives-to-the-sigmoid-activation" class="headerlink" title="Alternatives to the sigmoid activation"></a>Alternatives to the sigmoid activation</h4><p>ReLU: g(z)&#x3D;max(0,z)<br>Linear activation function: g(z)&#x3D;z</p>
<h4 id="Choosing-activation-function"><a href="#Choosing-activation-function" class="headerlink" title="Choosing activation function"></a>Choosing activation function</h4><ul>
<li>Output Layer:<br>Binary classification: Sigmoid<br>Regression: Linear(can be negative or positive)<br>Regression: ReLU(only positive)</li>
<li>Hidden Layer:<br>Most common choice: ReLU –&gt;faster<br>Binary classification: Sigmoid–&gt;flat, slow down learning</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> tensorflow,keras <span class="hljs-keyword">import</span> Dense<br>model = Sequential([<br>    Dense(units=<span class="hljs-number">25</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br>    Dense(units=<span class="hljs-number">15</span> activation=<span class="hljs-string">&#x27;relu&#x27;</span>),<br>    Dense(units=<span class="hljs-number">1</span> activation=<span class="hljs-string">&#x27;sigmoid&#x27;</span>),<br>                      ]) <br></code></pre></td></tr></table></figure>
<h4 id="Why-do-we-need-activation-functions"><a href="#Why-do-we-need-activation-functions" class="headerlink" title="Why do we need activation functions?"></a>Why do we need activation functions?</h4><p>Don’t use linear activations in hidden layers</p>
<h3 id="Multiclass"><a href="#Multiclass" class="headerlink" title="Multiclass"></a>Multiclass</h3><h4 id="Softmax"><a href="#Softmax" class="headerlink" title="Softmax"></a>Softmax</h4><p>Multiclass classification problem: target y can take on more than two possible values</p>
<ul>
<li>Softmax:<br><img src="/images/Softmax.png" srcset="/img/loading.gif" lazyload alt="pic" title="Softmax"></li>
<li>Cost:<br><img src="/images/Cost.png" srcset="/img/loading.gif" lazyload alt="pic" title="Cost"></li>
</ul>
<h4 id="Neural-Network-with-Softmax-output"><a href="#Neural-Network-with-Softmax-output" class="headerlink" title="Neural Network with Softmax output"></a>Neural Network with Softmax output</h4><p><img src="/images/Neural_Network_with_Softmax_output.png" srcset="/img/loading.gif" lazyload alt="pic" title="Neural Network with Softmax output"></p>
<ul>
<li>Property: Each of these activation values depends onn all of the values of z.</li>
<li>Sparse: each digit is th e only one of these catagories.<br><img src="/images/MNIST.png" srcset="/img/loading.gif" lazyload alt="pic" title="MNIST with softmax"></li>
</ul>
<h4 id="Improved-implementation-of-softmax"><a href="#Improved-implementation-of-softmax" class="headerlink" title="Improved implementation of softmax"></a>Improved implementation of softmax</h4><ul>
<li>Logistic regression:<br><img src="/images/Improved_implementation_of_Logistic_regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Improved implementation of Logistic regression"></li>
<li>Softmax regression:<br><img src="/images/Improved_implementation_of_Softmax_regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Improved implementation of Softmax regression"></li>
<li>Output layer use linear activation function: output z1~z10</li>
</ul>
<h4 id="Classification-with-multiple-outputs"><a href="#Classification-with-multiple-outputs" class="headerlink" title="Classification with multiple outputs"></a>Classification with multiple outputs</h4><p><img src="/images/Multilabel_Classification.png" srcset="/img/loading.gif" lazyload alt="pic" title="Multilabel Classification"></p>
<h3 id="Advanced-Optimization"><a href="#Advanced-Optimization" class="headerlink" title="Advanced Optimization"></a>Advanced Optimization</h3><ul>
<li>Adam algotithm: adjust α automatically<br><img src="/images/Adam.png" srcset="/img/loading.gif" lazyload alt="pic" title="MNIST Adam "></li>
</ul>
<h3 id="Addictional-Layer-Type"><a href="#Addictional-Layer-Type" class="headerlink" title="Addictional Layer Type"></a>Addictional Layer Type</h3><ul>
<li>Dense layer: every neuron in a layer gets as its inputs all the activations from the previous layer</li>
<li>Convolutional layer: Each neuron only looks at part of the previous layer’s outputs.<br>Why?</li>
<li>Faster computation</li>
<li>Need less training data(less prone to overfitting)<br><img src="/images/Convolutional_Neural_Network.png" srcset="/img/loading.gif" lazyload alt="pic" title="Convolutional Neural Network"></li>
</ul>
<h2 id="Pratical-advice-for-building-machine-learning-systems"><a href="#Pratical-advice-for-building-machine-learning-systems" class="headerlink" title="Pratical advice for building machine learning systems"></a>Pratical advice for building machine learning systems</h2><h3 id="Debugging-a-learning-algorithm"><a href="#Debugging-a-learning-algorithm" class="headerlink" title="Debugging a learning algorithm"></a>Debugging a learning algorithm</h3><p>When it makes unacceptably large errors in predictions.</p>
<ul>
<li>Get more training examples</li>
<li>Try smaller sets of features </li>
<li>Try getting additional features</li>
<li>Try adding polynomial features</li>
<li>Try decreasing lambda </li>
<li>Try increasing lambda<br>Diagnostic: A test that you run to gain insight into what is&#x2F;isn’t working with a learning algorithm, to gain guidance into improving its performance.</li>
</ul>
<h3 id="Evaluating-a-model"><a href="#Evaluating-a-model" class="headerlink" title="Evaluating a model"></a>Evaluating a model</h3><ul>
<li>Training Set</li>
<li>Test Set<br><img src="/images/Train/test_procedure_for_linear_regression.png" srcset="/img/loading.gif" lazyload alt="pic" title="Train&#x2F;test procedure for linear regression(with squared error cost"><br><img src="/images/Train/test_procedure_for_classification_problem.png" srcset="/img/loading.gif" lazyload alt="pic" title="Train&#x2F;test procedure for classification problem(with squared error cost"></li>
<li>fraction of the test set and the fraction of  the train set that the algorithm has misclassified–&gt;count y_hat ! &#x3D; y</li>
<li>J_test(w,b): the fraction of the test set that has been misclassified</li>
<li>J_train(w,b): the fraction of the train set that has been misclassified</li>
</ul>
<h4 id="Model-selection-and-training-cross-validation-test-sets"><a href="#Model-selection-and-training-cross-validation-test-sets" class="headerlink" title="Model selection and training&#x2F;cross validation&#x2F;test sets"></a>Model selection and training&#x2F;cross validation&#x2F;test sets</h4><p><img src="/images/Train/Model_Selection.png" srcset="/img/loading.gif" lazyload alt="pic" title="Train&#x2F;Model Selection"><br><img src="/images/Train/Cross_validation.png" srcset="/img/loading.gif" lazyload alt="pic" title="Training&#x2F;cross validation&#x2F;test set"></p>
<h4 id="Diagnosing-bias-and-variance"><a href="#Diagnosing-bias-and-variance" class="headerlink" title="Diagnosing bias and variance"></a>Diagnosing bias and variance</h4><h2 id="Decision-Trees"><a href="#Decision-Trees" class="headerlink" title="Decision Trees"></a>Decision Trees</h2>
                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Machine_learning</div>
      <div>http://example.com/2025/03/08/机器学习/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>pp</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2025年3月8日</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-cc-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2025/03/08/hello-world/" title="Hello World">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Hello World</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>目录</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/5.0.0/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
